---
title: "Project 3 - COVID19 Model"
author: "Margaret Gacheru, Joy Hsu, Melanie Mayer, Rachel Tsong, Adina Zhang"
date: "4/16/2020"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
require(drc)
```

Read in data:

```{r data}
covid19 <- read_csv("covid19-1.csv")
```

Explore data - NY Example:

```{r explore}
NY_dat = covid19 %>% filter(`Province/State` == "New York")

#Initialize column - time from 1st case
NY_dat$time_from_first_case <- rep(0, dim(NY_dat)[1])
#Find location of first confirmed case
case = sum(NY_dat$ConfirmedCases == 0)
#Fill in column
j = 1
for (i in (case+1):dim(NY_dat)[1]) {
  NY_dat$time_from_first_case[i] = j
  j = j+1
}

#Check whether logistic curve is good aproximation - cases
plot(ConfirmedCases ~ time_from_first_case, data = NY_dat) 

#Initialize column - time from 1st death
NY_dat$time_from_first_death <- rep(0, dim(NY_dat)[1])
#Find location of first confirmed case
deaths = sum(NY_dat$Fatalities == 0)
#Fill in column
j = 1
for (i in (deaths+1):dim(NY_dat)[1]) {
  NY_dat$time_from_first_death[i] = j
  j = j+1
}

#Check whether logistic curve is good aproximation - fatalities
plot(Fatalities ~ time_from_first_death, data = NY_dat) 

#Appears to have exponential growth, will try logistic growth model however
```

Estimation of logistic growth curve parameters using R functions:

```{r curve_params, eval = F}
model <- drc::drm(ConfirmedCases ~ time_from_first_case, fct = L.3(), data = NY_dat)
plot(model, log="", main = "Logistic function")

model <- drc::drm(Fatalities ~ time_from_first_death, fct = L.3(), data = NY_dat)
plot(model, log="", main = "Logistic function")

```

Create time from first case/fatality variables for entire dataset by Country/Region:

```{r data_cleaning}
#create desired variables, remove regions with less than 14 days with cases
covid19_country <- covid19 %>%
  group_by(`Country/Region`, Date) %>%
  summarise(ConfirmedCases = sum(ConfirmedCases),
            Fatalities = sum(Fatalities)) %>% 
  filter(ConfirmedCases != 0) %>%
  mutate(Date = as.Date(Date, format="%m/%d/%Y")) %>%
  arrange(`Country/Region`, Date) %>%
  mutate(
    time_from_first_case = ifelse(ConfirmedCases >= 1, 1, 0),
         time_from_first_case = cumsum(time_from_first_case),
         time_from_first_death = ifelse(Fatalities >= 1, 1, 0),
         time_from_first_death = cumsum(time_from_first_death)) %>%
  filter(max(time_from_first_case) >= 14)
```

Estimate Logistic Curve by Country/Region:

```{r estimates}
#Find estimates per country of cases - premade R function
cases_country_curves <- covid19_country %>%
  split(.$`Country/Region`) %>%
  map(~coefficients(drm(ConfirmedCases ~ time_from_first_case, fct = L.3(), data = .)))

cases_country_curves <- data.frame(matrix(unlist(cases_country_curves), nrow=length(cases_country_curves), byrow=T))

cases_country_curves <- cbind(cases_country_curves, Country = levels(factor(covid19_country$`Country/Region`))) %>%
  rename(B = "X1", A = "X2", C = "X3")


#Find estimates per country of fatalities - premade R function
#Fails to converge, use oy countries with time since first death >= 14
covid19_country_fatal <- covid19_country %>%
  filter(max(time_from_first_death) >= 14)
fatalities_country_curves <- covid19_country_fatal %>% 
  split(.$`Country/Region`) %>%
  map(~coefficients(drm(Fatalities ~ time_from_first_death, fct = L.3(), data = .)))

fatalities_country_curves <- data.frame(matrix(unlist(fatalities_country_curves), nrow=length(fatalities_country_curves), byrow=T))

fatalities_country_curves <- cbind(fatalities_country_curves, Country = levels(factor(covid19_country_fatal$`Country/Region`))) %>%
  rename(B = "X1", A = "X2", C = "X3")
```

## Task 2. Clustering your fitted Curves

#### K-mean Clustering:

- K clusters: $C_{1}, C_{2}, ...., C_{k}$
- Want to minimize within cluster correlation: minimize $$\sum_{k=1}^{K} W(C_{k})$$
- Define within cluster variance using the squared Euclidian distance:  $$W(C_{k}) = \frac{1}{|x|}\sum_{i,i' \in C_k}\sum_{j=1}^p(x_{ij}-x_{i'j})^2$$ where $|C_{k}|$ is the number of observations in cluster k

Algorithm:

1. Randomly choose k observations, use chosen observations' p observed values as centroid
2. Assign each observation to the cluster whose centroid is closest based on sum of p Euclidian distances
3. Compute p * k cluster means
3. Iterate step 2 & 3 until stop changing

```{r kmean}
kmeans_cluster <- function(X, k){
  #X: data frame
  #k: number of clusters desired
  p <- dim(X)[2]  # number of parameters
  n <- dim(X)[1]  # number of observations
  delta <- 1
  iter <- 0 
  itermax <- 30
  while(delta > 1e-4 && iter <= itermax){
    if(iter == 0){
      centroid <- X[sample(n, k),] #Initiate, randomly pick three observations, use values as centroid
      centroid_mem <- centroid
    }
    
    d <- sapply(1:k, function(c) sapply(1:n, 
      function(i) sum((centroid[c,] - X[i,])^2))) #sum of p Euclidian distances from k centroids per obs 
    
    cluster <- apply(d, 1, which.min) #Place obs. in cluster with smallest distance
    
    centroid <- t(sapply(1:k, function(c) 
      apply(X[cluster == c,], 2, mean))) # Compute new k*p centroids
    
    delta <- sum((centroid - centroid_mem)^2) #Check converegence
    iter <- iter + 1 
    centroid_mem <- centroid
  }
  X = cbind(X, cluster = cluster)
  return(list(centroid = centroid, cluster = cluster, df = X))
}

# run K-means
km <- kmeans_cluster(cases_country_curves[,1:3], 2)
pairs(cases_country_curves[,1:3], lower.panel = NULL, col = km$cluster)
summary(factor(km$cluster))

#Compare to package
km_pkg <- kmeans(cases_country_curves[,1:3], 2)
summary(factor(km_pkg$cluster))
km_pkg_vec <- cbind(cases_country_curves, cluster = km_pkg$cluster)

```

