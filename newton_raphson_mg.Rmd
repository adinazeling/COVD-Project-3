---
title: "newton_raphson_mg"
date: "4/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
require(drc)

```

First use US data:

```{r explore}
covid19 <- read_csv("covid19-1.csv")

covid19_country <- covid19 %>%
  group_by(`Country/Region`, Date) %>%
  summarise(ConfirmedCases = sum(ConfirmedCases),
            Fatalities = sum(Fatalities)) %>% 
  filter(ConfirmedCases != 0) %>%
  mutate(Date = as.Date(Date, format="%m/%d/%Y")) %>%
  arrange(`Country/Region`, Date) %>%
  mutate(
    time_from_first_case = ifelse(ConfirmedCases >= 1, 1, 0),
         time_from_first_case = cumsum(time_from_first_case),
         time_from_first_death = ifelse(Fatalities >= 1, 1, 0),
         time_from_first_death = cumsum(time_from_first_death)) %>%
  filter(max(time_from_first_case) >= 14)

US_dat = covid19_country%>%
  filter(`Country/Region` == "US")

```

Function that generates loss, gradient, and hessian

```{r}

# Write a function that generates loss, gradient and Hessian
# Inputs: 
# t - days since first case
# y - outcome
# par - vector containing a, b, and c parameters
func = function(t, y, par) {
  
  a = par[1]
  b = par[2]
  c = par[3]
  
  # Expu
  expu = exp(-b * (t - c))
  
  #avoid issues with grad = NaN and loss = Inf
  expu[expu == Inf] = 1000000000000
  
  # Loss function
  loss = -(1/2) * sum(y - (a / (1 + expu)))^2
  
  # First derivative matrix
  d1loss = vector(mode = "list")
  d1loss[[1]] = (1 / (1 + expu))
  d1loss[[2]] = (a * (c - t) * expu) / (1 + expu)^2
  d1loss[[3]] = (a * b * expu) / (1 + expu)^2
  
  # Gradient
  grad = vector(mode = "numeric", length = 3)
  
  grad[[1]] = -sum((y - (a / (1 + expu)) * d1loss[[1]]))
  grad[[2]] = sum((y - (a / (1 + expu)) * d1loss[[2]]))
  grad[[3]] = sum((y - (a / (1 + expu)) * d1loss[[3]]))
  
  hess = diag(3)
  
  return(list(loss = loss, grad = grad, Hess = hess)) 
}


```

Newton Raphson

```{r}

NewtonRaphson = function(y, t, main_function, start, tol = 1e-10, maxiter = 200) {
 
  i = 0
  cur = start
  lik_grad_hess = main_function(t, y, cur)
  res = c(0, lik_grad_hess$loss, cur)
  step = 1

  prevloss = -Inf # To make sure it iterates
  
  diff_loss = abs(lik_grad_hess$loss - prevloss)
  #if (is.nan(diff_loss)) { diff_loss <- 1e-2 }
  
  while(i < maxiter && diff_loss > tol) {
    i = i + 1
    
    prevlik_grad_hess = lik_grad_hess #time step i - 1
    prevloss = prevlik_grad_hess$loss
    prev = cur #step i - 1
    
    #ensure that the direction of the step is in ascent direction
    d_grad = - t(prevlik_grad_hess$grad) %*% prevlik_grad_hess$Hess %*% (prevlik_grad_hess$grad)
    n = ncol(prevlik_grad_hess$Hess)
    
    if (d_grad <= 0){
      
      max_eigen = max(eigen(lik_grad_hess$Hess)$values)
      prevlik_grad_hess$Hess = prevlik_grad_hess$Hess - (max_eigen + 0.1)*diag(n)
      
    }
    
    cur = prev - prevlik_grad_hess$Hess %*% prevlik_grad_hess$grad #step find theta for step i 
    lik_grad_hess = main_function(t, y, cur) #update log-lik, gradient, Hessian for step i 
  
    #half-step check
    while (lik_grad_hess$loss < prevloss) {
      
      step = 0.5*step
      cur = prev - step * lik_grad_hess$Hess %*% prevlik_grad_hess$grad
      lik_grad_hess = main_function(t, y, cur)

      }
    
    res = rbind(res, c(i, lik_grad_hess$loss, cur)) 
    
    diff_loss = abs(lik_grad_hess$loss - prevloss)
    if (is.nan(diff_loss)) { diff_loss <- 1e-2 }
    
    }
  
  return(res)
  
  }
```

Test newton raphson function: estimates for a, b, c very different depending on the start value (even with a small change)

```{r}

#what the data looks like and what would be reasonable choices for a, b, c
x = US_dat$time_from_first_case
plot(x = US_dat$time_from_first_case, y = US_dat$ConfirmedCases)
lines(x, 1000000/(1+exp(-0.4*(x - 36))))

#possible "right answer": a = 1000000, b = 0.4, c = 36

#this works
test1 = NewtonRaphson(y = US_dat$ConfirmedCases, t = US_dat$time_from_first_case, func, c(1000000, 0.35, 40))
colnames(test1) = c("iteration","-loss", "a", "b", "c")
test1

#this sort of works
test2 = NewtonRaphson(y = US_dat$ConfirmedCases, t = US_dat$time_from_first_case, func, c(1000000, 0.4, 70))
colnames(test2) = c("iteration","-loss", "a", "b", "c")
test2

#this breaks
test3 = NewtonRaphson(y = US_dat$ConfirmedCases, t = US_dat$time_from_first_case, func, c(1000000, 2, 50))
colnames(test3) = c("iteration","-loss", "a", "b", "c")
test3

#this breaks
test4 = NewtonRaphson(y = US_dat$ConfirmedCases, t = US_dat$time_from_first_case, func, c(1000000, 0.1, 40))
colnames(test4) = c("iteration","-loss", "a", "b", "c")
test4

```


```{r}

Chick.1 <- ChickWeight[ChickWeight$Chick == 1, ]
SSlogis(Chick.1$Time, 368, 14, 6)  # response only
local({
  Asym <- 368; xmid <- 14; scal <- 6
  SSlogis(Chick.1$Time, Asym, xmid, scal) # response _and_ gradient
})
getInitial(weight ~ SSlogis(Time, Asym, xmid, scal), data = Chick.1)
## Initial values are in fact the converged one here, "Number of iter...: 0" :
fm1 <- nls(weight ~ SSlogis(Time, Asym, xmid, scal), data = Chick.1)
summary(fm1)
## but are slightly improved here:
fm2 <- update(fm1, control=nls.control(tol = 1e-9, warnOnly=TRUE), trace = TRUE)
all.equal(coef(fm1), coef(fm2)) # "Mean relative difference: 9.6e-6"
str(fm2$convInfo) # 3 iterations
# }
# NOT RUN {

# }
```

nls

```{r}

x = c(60, 80, 100, 140, 160, 180)
y = c(24.0688, 26.3774, 25.1653, 15.7559, 12.4160, 15.5849)

df = data.frame(x=x, y=y)
nls(y ~ SSlogis(x, Asym, xmid, scal), df)

```

